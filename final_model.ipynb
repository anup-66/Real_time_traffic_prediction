{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "53c522c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import warnings\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1336f0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anup\\AppData\\Local\\Temp\\ipykernel_24048\\1525057717.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features['timestamp'] = pd.to_datetime(features['timestamp'])\n",
      "C:\\Users\\Anup\\AppData\\Local\\Temp\\ipykernel_24048\\1525057717.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features['month'] = features['timestamp'].dt.month\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"traffic_data.csv\")\n",
    "features = data[['timestamp', 'intensity', 'velocity', 'lat', 'long', 'tweet count', 'weather','target']]\n",
    "features['timestamp'] = pd.to_datetime(features['timestamp'])\n",
    "features['month'] = features['timestamp'].dt.month\n",
    "features['day'] = features['timestamp'].dt.day\n",
    "features['hour'] = features['timestamp'].dt.hour\n",
    "features = features.drop('timestamp', axis=1)\n",
    "lat = features['lat']\n",
    "long = features['long']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a17f22d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intensity</th>\n",
       "      <th>velocity</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>tweet count</th>\n",
       "      <th>weather</th>\n",
       "      <th>target</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5520</td>\n",
       "      <td>80</td>\n",
       "      <td>-3.674076</td>\n",
       "      <td>40.48064</td>\n",
       "      <td>9</td>\n",
       "      <td>partly-cloudy-night</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5640</td>\n",
       "      <td>80</td>\n",
       "      <td>-3.674076</td>\n",
       "      <td>40.48064</td>\n",
       "      <td>32</td>\n",
       "      <td>partly-cloudy-night</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5880</td>\n",
       "      <td>78</td>\n",
       "      <td>-3.674076</td>\n",
       "      <td>40.48064</td>\n",
       "      <td>51</td>\n",
       "      <td>partly-cloudy-night</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5580</td>\n",
       "      <td>80</td>\n",
       "      <td>-3.674076</td>\n",
       "      <td>40.48064</td>\n",
       "      <td>32</td>\n",
       "      <td>partly-cloudy-night</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4980</td>\n",
       "      <td>78</td>\n",
       "      <td>-3.674076</td>\n",
       "      <td>40.48064</td>\n",
       "      <td>55</td>\n",
       "      <td>partly-cloudy-night</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   intensity  velocity       lat      long  tweet count              weather  \\\n",
       "0       5520        80 -3.674076  40.48064            9  partly-cloudy-night   \n",
       "1       5640        80 -3.674076  40.48064           32  partly-cloudy-night   \n",
       "2       5880        78 -3.674076  40.48064           51  partly-cloudy-night   \n",
       "3       5580        80 -3.674076  40.48064           32  partly-cloudy-night   \n",
       "4       4980        78 -3.674076  40.48064           55  partly-cloudy-night   \n",
       "\n",
       "   target  month  day  hour  \n",
       "0       1      5   11     9  \n",
       "1       1      5   11     9  \n",
       "2       1      5   11     9  \n",
       "3       1      5   11     9  \n",
       "4       1      5   11    10  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f6975660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['partly-cloudy-night' 'clear-night' 'clear-day' 'partly-cloudy-day'\n",
      " 'cloudy' 'rain' 'fog']\n"
     ]
    }
   ],
   "source": [
    "unique_values_1 = features['weather'].unique()\n",
    "print(unique_values_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0197c91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {value: i for i, value in enumerate(unique_values_1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "df40cef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "features['weather'] = features['weather'].replace(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "32fc5222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intensity</th>\n",
       "      <th>velocity</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>tweet count</th>\n",
       "      <th>weather</th>\n",
       "      <th>target</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5520</td>\n",
       "      <td>80</td>\n",
       "      <td>-3.674076</td>\n",
       "      <td>40.48064</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5640</td>\n",
       "      <td>80</td>\n",
       "      <td>-3.674076</td>\n",
       "      <td>40.48064</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5880</td>\n",
       "      <td>78</td>\n",
       "      <td>-3.674076</td>\n",
       "      <td>40.48064</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5580</td>\n",
       "      <td>80</td>\n",
       "      <td>-3.674076</td>\n",
       "      <td>40.48064</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4980</td>\n",
       "      <td>78</td>\n",
       "      <td>-3.674076</td>\n",
       "      <td>40.48064</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   intensity  velocity       lat      long  tweet count  weather  target  \\\n",
       "0       5520        80 -3.674076  40.48064            9        0       1   \n",
       "1       5640        80 -3.674076  40.48064           32        0       1   \n",
       "2       5880        78 -3.674076  40.48064           51        0       1   \n",
       "3       5580        80 -3.674076  40.48064           32        0       1   \n",
       "4       4980        78 -3.674076  40.48064           55        0       1   \n",
       "\n",
       "   month  day  hour  \n",
       "0      5   11     9  \n",
       "1      5   11     9  \n",
       "2      5   11     9  \n",
       "3      5   11     9  \n",
       "4      5   11    10  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ce5c8c79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intensity</th>\n",
       "      <th>velocity</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>tweet count</th>\n",
       "      <th>weather</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5520</td>\n",
       "      <td>80</td>\n",
       "      <td>-3.674076</td>\n",
       "      <td>40.48064</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5640</td>\n",
       "      <td>80</td>\n",
       "      <td>-3.674076</td>\n",
       "      <td>40.48064</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5880</td>\n",
       "      <td>78</td>\n",
       "      <td>-3.674076</td>\n",
       "      <td>40.48064</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5580</td>\n",
       "      <td>80</td>\n",
       "      <td>-3.674076</td>\n",
       "      <td>40.48064</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4980</td>\n",
       "      <td>78</td>\n",
       "      <td>-3.674076</td>\n",
       "      <td>40.48064</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6017</th>\n",
       "      <td>1140</td>\n",
       "      <td>70</td>\n",
       "      <td>-3.674579</td>\n",
       "      <td>40.47598</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6018</th>\n",
       "      <td>1080</td>\n",
       "      <td>72</td>\n",
       "      <td>-3.674579</td>\n",
       "      <td>40.47598</td>\n",
       "      <td>53</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6019</th>\n",
       "      <td>1260</td>\n",
       "      <td>74</td>\n",
       "      <td>-3.674579</td>\n",
       "      <td>40.47598</td>\n",
       "      <td>53</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6020</th>\n",
       "      <td>1320</td>\n",
       "      <td>73</td>\n",
       "      <td>-3.674579</td>\n",
       "      <td>40.47598</td>\n",
       "      <td>53</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6021</th>\n",
       "      <td>780</td>\n",
       "      <td>83</td>\n",
       "      <td>-3.674579</td>\n",
       "      <td>40.47598</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6022 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      intensity  velocity       lat      long  tweet count  weather  day  hour\n",
       "0          5520        80 -3.674076  40.48064            9        0   11     9\n",
       "1          5640        80 -3.674076  40.48064           32        0   11     9\n",
       "2          5880        78 -3.674076  40.48064           51        0   11     9\n",
       "3          5580        80 -3.674076  40.48064           32        0   11     9\n",
       "4          4980        78 -3.674076  40.48064           55        0   11    10\n",
       "...         ...       ...       ...       ...          ...      ...  ...   ...\n",
       "6017       1140        70 -3.674579  40.47598           60        3   25    18\n",
       "6018       1080        72 -3.674579  40.47598           53        3   25    18\n",
       "6019       1260        74 -3.674579  40.47598           53        3   25    19\n",
       "6020       1320        73 -3.674579  40.47598           53        3   25    19\n",
       "6021        780        83 -3.674579  40.47598           23        1   26     7\n",
       "\n",
       "[6022 rows x 8 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = features['target']\n",
    "features = features.drop(['target','month'],axis=1)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "554e0afd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intensity</th>\n",
       "      <th>velocity</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>tweet count</th>\n",
       "      <th>weather</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5520</td>\n",
       "      <td>80</td>\n",
       "      <td>-3.674076</td>\n",
       "      <td>40.48064</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5640</td>\n",
       "      <td>80</td>\n",
       "      <td>-3.674076</td>\n",
       "      <td>40.48064</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5880</td>\n",
       "      <td>78</td>\n",
       "      <td>-3.674076</td>\n",
       "      <td>40.48064</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5580</td>\n",
       "      <td>80</td>\n",
       "      <td>-3.674076</td>\n",
       "      <td>40.48064</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4980</td>\n",
       "      <td>78</td>\n",
       "      <td>-3.674076</td>\n",
       "      <td>40.48064</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   intensity  velocity       lat      long  tweet count  weather  day  hour\n",
       "0       5520        80 -3.674076  40.48064            9        0   11     9\n",
       "1       5640        80 -3.674076  40.48064           32        0   11     9\n",
       "2       5880        78 -3.674076  40.48064           51        0   11     9\n",
       "3       5580        80 -3.674076  40.48064           32        0   11     9\n",
       "4       4980        78 -3.674076  40.48064           55        0   11    10"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e9d99c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1483    0\n",
      "4703    1\n",
      "5766    0\n",
      "2788    0\n",
      "4139    1\n",
      "Name: target, dtype: int64\n",
      "Epoch 1/100\n",
      "151/151 [==============================] - 6s 4ms/step - loss: 0.6321 - accuracy: 0.6591\n",
      "Epoch 2/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.5243 - accuracy: 0.7168\n",
      "Epoch 3/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.4806 - accuracy: 0.7565\n",
      "Epoch 4/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.4527 - accuracy: 0.7845\n",
      "Epoch 5/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.4346 - accuracy: 0.7893\n",
      "Epoch 6/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.4295 - accuracy: 0.7939\n",
      "Epoch 7/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.4171 - accuracy: 0.8028\n",
      "Epoch 8/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.4131 - accuracy: 0.8117\n",
      "Epoch 9/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.4059 - accuracy: 0.8169\n",
      "Epoch 10/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.4002 - accuracy: 0.8186\n",
      "Epoch 11/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.3924 - accuracy: 0.8240\n",
      "Epoch 12/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.3890 - accuracy: 0.8256\n",
      "Epoch 13/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.3932 - accuracy: 0.8233\n",
      "Epoch 14/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.3836 - accuracy: 0.8262\n",
      "Epoch 15/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.3793 - accuracy: 0.8308\n",
      "Epoch 16/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.3757 - accuracy: 0.8314\n",
      "Epoch 17/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.3771 - accuracy: 0.8329\n",
      "Epoch 18/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.3780 - accuracy: 0.8316\n",
      "Epoch 19/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.3742 - accuracy: 0.8339\n",
      "Epoch 20/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.3713 - accuracy: 0.8335\n",
      "Epoch 21/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.3694 - accuracy: 0.8335\n",
      "Epoch 22/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.3702 - accuracy: 0.8372\n",
      "Epoch 23/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.3654 - accuracy: 0.8412\n",
      "Epoch 24/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.3650 - accuracy: 0.8420\n",
      "Epoch 25/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.3641 - accuracy: 0.8385\n",
      "Epoch 26/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.3623 - accuracy: 0.8389\n",
      "Epoch 27/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.3630 - accuracy: 0.8441\n",
      "Epoch 28/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.3625 - accuracy: 0.8418\n",
      "Epoch 29/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.3611 - accuracy: 0.8422\n",
      "Epoch 30/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.3615 - accuracy: 0.8458\n",
      "Epoch 31/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.3575 - accuracy: 0.8412\n",
      "Epoch 32/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.3591 - accuracy: 0.8495\n",
      "Epoch 33/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.3657 - accuracy: 0.8447\n",
      "Epoch 34/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.3589 - accuracy: 0.8445\n",
      "Epoch 35/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.3563 - accuracy: 0.8449\n",
      "Epoch 36/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.3570 - accuracy: 0.8437\n",
      "Epoch 37/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.3532 - accuracy: 0.8472\n",
      "Epoch 38/100\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 0.3615 - accuracy: 0.8414\n",
      "Epoch 39/100\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 0.3576 - accuracy: 0.8462\n",
      "Epoch 40/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.3513 - accuracy: 0.8480\n",
      "Epoch 41/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.3552 - accuracy: 0.8518\n",
      "Epoch 42/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.3575 - accuracy: 0.8472\n",
      "Epoch 43/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.3530 - accuracy: 0.8462\n",
      "Epoch 44/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.3546 - accuracy: 0.8468\n",
      "Epoch 45/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.3533 - accuracy: 0.8480\n",
      "Epoch 46/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.3596 - accuracy: 0.8466\n",
      "Epoch 47/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.3497 - accuracy: 0.8520\n",
      "Epoch 48/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.3514 - accuracy: 0.8460\n",
      "Epoch 49/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.3519 - accuracy: 0.8487\n",
      "Epoch 50/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.3466 - accuracy: 0.8520\n",
      "Epoch 51/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.3486 - accuracy: 0.8524\n",
      "Epoch 52/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.3484 - accuracy: 0.8514\n",
      "Epoch 53/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.3525 - accuracy: 0.8485\n",
      "Epoch 54/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.3456 - accuracy: 0.8507\n",
      "Epoch 55/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.3462 - accuracy: 0.8522\n",
      "Epoch 56/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.3467 - accuracy: 0.8565\n",
      "Epoch 57/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.3491 - accuracy: 0.8497\n",
      "Epoch 58/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.3446 - accuracy: 0.8541\n",
      "Epoch 59/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.3407 - accuracy: 0.8582\n",
      "Epoch 60/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.3425 - accuracy: 0.8553\n",
      "Epoch 61/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.3419 - accuracy: 0.8555\n",
      "Epoch 62/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.3446 - accuracy: 0.8547\n",
      "Epoch 63/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.3395 - accuracy: 0.8553\n",
      "Epoch 64/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.3430 - accuracy: 0.8578\n",
      "Epoch 65/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.3438 - accuracy: 0.8553\n",
      "Epoch 66/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.3418 - accuracy: 0.8578\n",
      "Epoch 67/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.3401 - accuracy: 0.8590\n",
      "Epoch 68/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.3367 - accuracy: 0.8563\n",
      "Epoch 69/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.3376 - accuracy: 0.8565\n",
      "Epoch 70/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.3383 - accuracy: 0.8559\n",
      "Epoch 71/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.3365 - accuracy: 0.8572\n",
      "Epoch 72/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.3372 - accuracy: 0.8609\n",
      "Epoch 73/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.3372 - accuracy: 0.8597\n",
      "Epoch 74/100\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 0.3359 - accuracy: 0.8586\n",
      "Epoch 75/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.3346 - accuracy: 0.8588\n",
      "Epoch 76/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.3333 - accuracy: 0.8607\n",
      "Epoch 77/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.3332 - accuracy: 0.8599\n",
      "Epoch 78/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.3313 - accuracy: 0.8634\n",
      "Epoch 79/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.3349 - accuracy: 0.8590\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151/151 [==============================] - 1s 5ms/step - loss: 0.3308 - accuracy: 0.8628\n",
      "Epoch 81/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.3314 - accuracy: 0.8599\n",
      "Epoch 82/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.3278 - accuracy: 0.8632\n",
      "Epoch 83/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.3323 - accuracy: 0.8588\n",
      "Epoch 84/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.3312 - accuracy: 0.8607\n",
      "Epoch 85/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.3292 - accuracy: 0.8638\n",
      "Epoch 86/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.3254 - accuracy: 0.8655\n",
      "Epoch 87/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.3243 - accuracy: 0.8657\n",
      "Epoch 88/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.3246 - accuracy: 0.8669\n",
      "Epoch 89/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.3260 - accuracy: 0.8676\n",
      "Epoch 90/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.3262 - accuracy: 0.8644\n",
      "Epoch 91/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.3245 - accuracy: 0.8640\n",
      "Epoch 92/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.3237 - accuracy: 0.8651\n",
      "Epoch 93/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.3250 - accuracy: 0.8649\n",
      "Epoch 94/100\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.3211 - accuracy: 0.8676\n",
      "Epoch 95/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.3247 - accuracy: 0.8649\n",
      "Epoch 96/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.3216 - accuracy: 0.8628\n",
      "Epoch 97/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.3224 - accuracy: 0.8671\n",
      "Epoch 98/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.3222 - accuracy: 0.8711\n",
      "Epoch 99/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.3219 - accuracy: 0.8694\n",
      "Epoch 100/100\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.3195 - accuracy: 0.8711\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d576ae8f40>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import LSTM, Dense\n",
    "# import numpy as np\n",
    "\n",
    "# Preprocess the data\n",
    "scaler = MinMaxScaler()\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_features, target, test_size=0.2, random_state=42)\n",
    "print(y_train[:5])\n",
    "# Reshape the input data for LSTM\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "# model.add(LSTM(128, input_shape=(1, X_train.shape[2])))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#modified :\n",
    "model.add(LSTM(64, input_shape=(1, X_train.shape[2]), return_sequences=True))\n",
    "model.add(LSTM(64, return_sequences=True))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# Compile and train the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4d12ead6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n",
      "Prediction: Congestion chances: [[0.96141136]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assuming you have a single data point to predict\n",
    "data_point = np.array([[5520,80,-3.674076,\t40.480649,21,0,11,9]])  # Replace ... with your data\n",
    "\n",
    "# Scale and reshape the data point\n",
    "# scaled_data_point = scaler.transform(data_point)\n",
    "# reshaped_data_point = np.reshape(scaled_data_point, (1, 1, scaled_data_point.shape[1]))\n",
    "\n",
    "# # Predict using the trained model\n",
    "# prediction = model.predict(reshaped_data_point)\n",
    "\n",
    "scaled_data_point = scaler.transform(data_point)\n",
    "reshaped_data_point = np.reshape(scaled_data_point, (1, 1, scaled_data_point.shape[1]))\n",
    "\n",
    "# Predict using the trained model\n",
    "prediction = model.predict(reshaped_data_point)\n",
    "# Convert the prediction to congestion or not\n",
    "if prediction > 0.5:\n",
    "    congestion = f\"Congestion chances: {prediction}\"\n",
    "else:\n",
    "    congestion = f\"No Congestion {prediction}\"\n",
    "\n",
    "# Print the prediction\n",
    "print(\"Prediction:\", congestion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d6751ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# with open('fmodel.pkl','wb') as f:\n",
    "#     pickle.dump(model,f)\n",
    "\n",
    "with open('scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e6629cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huhuhuh\n",
      "Epoch 1/50\n",
      "121/121 [==============================] - 4s 19ms/step - loss: 0.6500 - accuracy: 0.6520 - val_loss: 0.6347 - val_accuracy: 0.6805\n",
      "Epoch 2/50\n",
      "121/121 [==============================] - 2s 13ms/step - loss: 0.6437 - accuracy: 0.6520 - val_loss: 0.6197 - val_accuracy: 0.6805\n",
      "Epoch 3/50\n",
      "121/121 [==============================] - 2s 13ms/step - loss: 0.6361 - accuracy: 0.6520 - val_loss: 0.6059 - val_accuracy: 0.6805\n",
      "Epoch 4/50\n",
      "121/121 [==============================] - 2s 16ms/step - loss: 0.6258 - accuracy: 0.6512 - val_loss: 0.5895 - val_accuracy: 0.6857\n",
      "Epoch 5/50\n",
      "121/121 [==============================] - 2s 14ms/step - loss: 0.5530 - accuracy: 0.7028 - val_loss: 0.5474 - val_accuracy: 0.7199\n",
      "Epoch 6/50\n",
      "121/121 [==============================] - 2s 12ms/step - loss: 0.5335 - accuracy: 0.7137 - val_loss: 0.4883 - val_accuracy: 0.7490\n",
      "Epoch 7/50\n",
      "121/121 [==============================] - 2s 13ms/step - loss: 0.5097 - accuracy: 0.7311 - val_loss: 0.4725 - val_accuracy: 0.7552\n",
      "Epoch 8/50\n",
      "121/121 [==============================] - 1s 12ms/step - loss: 0.4936 - accuracy: 0.7446 - val_loss: 0.4731 - val_accuracy: 0.7573\n",
      "Epoch 9/50\n",
      "121/121 [==============================] - 1s 11ms/step - loss: 0.4981 - accuracy: 0.7410 - val_loss: 0.4693 - val_accuracy: 0.7728\n",
      "Epoch 10/50\n",
      "121/121 [==============================] - 1s 12ms/step - loss: 0.4780 - accuracy: 0.7584 - val_loss: 0.4612 - val_accuracy: 0.7707\n",
      "Epoch 11/50\n",
      "121/121 [==============================] - 1s 12ms/step - loss: 0.4627 - accuracy: 0.7763 - val_loss: 0.4318 - val_accuracy: 0.7925\n",
      "Epoch 12/50\n",
      "121/121 [==============================] - 1s 12ms/step - loss: 0.4615 - accuracy: 0.7719 - val_loss: 0.4307 - val_accuracy: 0.7956\n",
      "Epoch 13/50\n",
      "121/121 [==============================] - 1s 12ms/step - loss: 0.4448 - accuracy: 0.7815 - val_loss: 0.4124 - val_accuracy: 0.8071\n",
      "Epoch 14/50\n",
      "121/121 [==============================] - 2s 13ms/step - loss: 0.4532 - accuracy: 0.7703 - val_loss: 0.4348 - val_accuracy: 0.8039\n",
      "Epoch 15/50\n",
      "121/121 [==============================] - 2s 13ms/step - loss: 0.4325 - accuracy: 0.7942 - val_loss: 0.4064 - val_accuracy: 0.8216\n",
      "Epoch 16/50\n",
      "121/121 [==============================] - 1s 12ms/step - loss: 0.4257 - accuracy: 0.7981 - val_loss: 0.3984 - val_accuracy: 0.8205\n",
      "Epoch 17/50\n",
      "121/121 [==============================] - 1s 11ms/step - loss: 0.4187 - accuracy: 0.8048 - val_loss: 0.3885 - val_accuracy: 0.8247\n",
      "Epoch 18/50\n",
      "121/121 [==============================] - 1s 12ms/step - loss: 0.4188 - accuracy: 0.8046 - val_loss: 0.4238 - val_accuracy: 0.7925\n",
      "Epoch 19/50\n",
      "121/121 [==============================] - 1s 12ms/step - loss: 0.4095 - accuracy: 0.8098 - val_loss: 0.3855 - val_accuracy: 0.8268\n",
      "Epoch 20/50\n",
      "121/121 [==============================] - 2s 13ms/step - loss: 0.4039 - accuracy: 0.8129 - val_loss: 0.3863 - val_accuracy: 0.8268\n",
      "Epoch 21/50\n",
      "121/121 [==============================] - 1s 12ms/step - loss: 0.4003 - accuracy: 0.8212 - val_loss: 0.3852 - val_accuracy: 0.8361\n",
      "Epoch 22/50\n",
      "121/121 [==============================] - 1s 12ms/step - loss: 0.3970 - accuracy: 0.8222 - val_loss: 0.3730 - val_accuracy: 0.8371\n",
      "Epoch 23/50\n",
      "121/121 [==============================] - 2s 13ms/step - loss: 0.4017 - accuracy: 0.8160 - val_loss: 0.3735 - val_accuracy: 0.8465\n",
      "Epoch 24/50\n",
      "121/121 [==============================] - 2s 13ms/step - loss: 0.3950 - accuracy: 0.8199 - val_loss: 0.3746 - val_accuracy: 0.8330\n",
      "Epoch 25/50\n",
      "121/121 [==============================] - 2s 12ms/step - loss: 0.3893 - accuracy: 0.8331 - val_loss: 0.3838 - val_accuracy: 0.8216\n",
      "Epoch 26/50\n",
      "121/121 [==============================] - 1s 12ms/step - loss: 0.3849 - accuracy: 0.8207 - val_loss: 0.3897 - val_accuracy: 0.8185\n",
      "Epoch 27/50\n",
      "121/121 [==============================] - 1s 12ms/step - loss: 0.3838 - accuracy: 0.8274 - val_loss: 0.3672 - val_accuracy: 0.8361\n",
      "Epoch 28/50\n",
      "121/121 [==============================] - 1s 12ms/step - loss: 0.3821 - accuracy: 0.8259 - val_loss: 0.3705 - val_accuracy: 0.8434\n",
      "Epoch 29/50\n",
      "121/121 [==============================] - 2s 13ms/step - loss: 0.3801 - accuracy: 0.8297 - val_loss: 0.4163 - val_accuracy: 0.8071\n",
      "Epoch 30/50\n",
      "121/121 [==============================] - 1s 12ms/step - loss: 0.3858 - accuracy: 0.8271 - val_loss: 0.3694 - val_accuracy: 0.8351\n",
      "Epoch 31/50\n",
      "121/121 [==============================] - 2s 19ms/step - loss: 0.3835 - accuracy: 0.8323 - val_loss: 0.3795 - val_accuracy: 0.8309\n",
      "Epoch 32/50\n",
      "121/121 [==============================] - 2s 13ms/step - loss: 0.3876 - accuracy: 0.8230 - val_loss: 0.3673 - val_accuracy: 0.8392\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\Anup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1852, in test_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Anup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1836, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Anup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1824, in run_step  **\n        outputs = model.test_step(data)\n    File \"C:\\Users\\Anup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1788, in test_step\n        y_pred = self(x, training=False)\n    File \"C:\\Users\\Anup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\Anup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\layers\\rnn\\lstm.py\", line 615, in call\n        timesteps = input_shape[0] if self.time_major else input_shape[1]\n\n    TypeError: Exception encountered when calling layer 'lstm_9' (type LSTM).\n    \n    'NoneType' object is not subscriptable\n    \n    Call arguments received by layer 'lstm_9' (type LSTM):\n      • inputs=tf.Tensor(shape=<unknown>, dtype=float32)\n      • mask=None\n      • training=False\n      • initial_state=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 45>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     42\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(X_val, y_val), callbacks\u001b[38;5;241m=\u001b[39m[early_stopping])\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Evaluate the model on the test set\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Loss:\u001b[39m\u001b[38;5;124m\"\u001b[39m, loss)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Accuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, accuracy)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filefv473mbv.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__test_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: in user code:\n\n    File \"C:\\Users\\Anup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1852, in test_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Anup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1836, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Anup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1824, in run_step  **\n        outputs = model.test_step(data)\n    File \"C:\\Users\\Anup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1788, in test_step\n        y_pred = self(x, training=False)\n    File \"C:\\Users\\Anup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\Anup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\layers\\rnn\\lstm.py\", line 615, in call\n        timesteps = input_shape[0] if self.time_major else input_shape[1]\n\n    TypeError: Exception encountered when calling layer 'lstm_9' (type LSTM).\n    \n    'NoneType' object is not subscriptable\n    \n    Call arguments received by layer 'lstm_9' (type LSTM):\n      • inputs=tf.Tensor(shape=<unknown>, dtype=float32)\n      • mask=None\n      • training=False\n      • initial_state=None\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_features, target, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape the input data for LSTM\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "#modified\n",
    "\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "model.add(LSTM(64, input_shape=(1, X_train.shape[2]), return_sequences=True))\n",
    "model.add(LSTM(64, return_sequences=True))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9eedce9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"uhuh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14f677cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('scaler.pkl', 'wb') as f:\n",
    "#     pickle.dump(scaler, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "20c26977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n",
      "[[0.96141136]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Scale and reshape the data point\n",
    "with open('Api/scaler.pkl', 'rb') as f:\n",
    "    scaler = pickle.load(f)\n",
    "\n",
    "scaled_data_point = scaler.transform(data_point)\n",
    "reshaped_data_point = np.reshape(scaled_data_point, (1, 1, scaled_data_point.shape[1]))\n",
    "\n",
    "# Predict using the trained model\n",
    "prediction = model.predict(reshaped_data_point)\n",
    "\n",
    "# a = model.predict(ll)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "364e490b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "121/121 [==============================] - 7s 29ms/step - loss: 0.6559 - accuracy: 0.6481 - val_loss: 0.6359 - val_accuracy: 0.6805\n",
      "Epoch 2/50\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6476 - accuracy: 0.6520 - val_loss: 0.6257 - val_accuracy: 0.6805\n",
      "Epoch 3/50\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6459 - accuracy: 0.6520 - val_loss: 0.6234 - val_accuracy: 0.6805\n",
      "Epoch 4/50\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6395 - accuracy: 0.6507 - val_loss: 0.6167 - val_accuracy: 0.6784\n",
      "Epoch 5/50\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.6096 - accuracy: 0.6540 - val_loss: 0.5528 - val_accuracy: 0.7210\n",
      "Epoch 6/50\n",
      "121/121 [==============================] - 3s 27ms/step - loss: 0.5318 - accuracy: 0.7257 - val_loss: 0.4558 - val_accuracy: 0.7697\n",
      "Epoch 7/50\n",
      "121/121 [==============================] - 3s 25ms/step - loss: 0.4984 - accuracy: 0.7482 - val_loss: 0.4741 - val_accuracy: 0.7490\n",
      "Epoch 8/50\n",
      "121/121 [==============================] - 3s 25ms/step - loss: 0.4760 - accuracy: 0.7573 - val_loss: 0.4544 - val_accuracy: 0.7905\n",
      "Epoch 9/50\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.4509 - accuracy: 0.7773 - val_loss: 0.4260 - val_accuracy: 0.7873\n",
      "Epoch 10/50\n",
      "121/121 [==============================] - 3s 25ms/step - loss: 0.4556 - accuracy: 0.7672 - val_loss: 0.4305 - val_accuracy: 0.8008\n",
      "Epoch 11/50\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.4347 - accuracy: 0.7929 - val_loss: 0.4733 - val_accuracy: 0.7853\n",
      "Epoch 12/50\n",
      "121/121 [==============================] - 3s 24ms/step - loss: 0.4405 - accuracy: 0.7903 - val_loss: 0.4079 - val_accuracy: 0.8081\n",
      "Epoch 13/50\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.4267 - accuracy: 0.7983 - val_loss: 0.4210 - val_accuracy: 0.7842\n",
      "Epoch 14/50\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.4279 - accuracy: 0.7942 - val_loss: 0.4244 - val_accuracy: 0.7801\n",
      "Epoch 15/50\n",
      "121/121 [==============================] - 3s 25ms/step - loss: 0.4191 - accuracy: 0.8048 - val_loss: 0.3880 - val_accuracy: 0.8299\n",
      "Epoch 16/50\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.4165 - accuracy: 0.8025 - val_loss: 0.3922 - val_accuracy: 0.8247\n",
      "Epoch 17/50\n",
      "121/121 [==============================] - 3s 24ms/step - loss: 0.3953 - accuracy: 0.8204 - val_loss: 0.4337 - val_accuracy: 0.7936\n",
      "Epoch 18/50\n",
      "121/121 [==============================] - 3s 25ms/step - loss: 0.4013 - accuracy: 0.8113 - val_loss: 0.3969 - val_accuracy: 0.8071\n",
      "Epoch 19/50\n",
      "121/121 [==============================] - 3s 24ms/step - loss: 0.3977 - accuracy: 0.8147 - val_loss: 0.4228 - val_accuracy: 0.7977\n",
      "Epoch 20/50\n",
      "121/121 [==============================] - 3s 25ms/step - loss: 0.3964 - accuracy: 0.8162 - val_loss: 0.3660 - val_accuracy: 0.8475\n",
      "Epoch 21/50\n",
      "121/121 [==============================] - 3s 24ms/step - loss: 0.3908 - accuracy: 0.8183 - val_loss: 0.3618 - val_accuracy: 0.8496\n",
      "Epoch 22/50\n",
      "121/121 [==============================] - 3s 25ms/step - loss: 0.3843 - accuracy: 0.8266 - val_loss: 0.3667 - val_accuracy: 0.8475\n",
      "Epoch 23/50\n",
      "121/121 [==============================] - 3s 25ms/step - loss: 0.3774 - accuracy: 0.8334 - val_loss: 0.3625 - val_accuracy: 0.8496\n",
      "Epoch 24/50\n",
      "121/121 [==============================] - 3s 25ms/step - loss: 0.3825 - accuracy: 0.8282 - val_loss: 0.3734 - val_accuracy: 0.8434\n",
      "Epoch 25/50\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.3780 - accuracy: 0.8334 - val_loss: 0.4061 - val_accuracy: 0.8143\n",
      "Epoch 26/50\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.3732 - accuracy: 0.8290 - val_loss: 0.3580 - val_accuracy: 0.8506\n",
      "Epoch 27/50\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.3643 - accuracy: 0.8344 - val_loss: 0.3591 - val_accuracy: 0.8413\n",
      "Epoch 28/50\n",
      "121/121 [==============================] - 3s 23ms/step - loss: 0.3648 - accuracy: 0.8357 - val_loss: 0.3691 - val_accuracy: 0.8361\n",
      "Epoch 29/50\n",
      "121/121 [==============================] - 3s 24ms/step - loss: 0.3639 - accuracy: 0.8386 - val_loss: 0.3521 - val_accuracy: 0.8568\n",
      "Epoch 30/50\n",
      "121/121 [==============================] - 3s 24ms/step - loss: 0.3564 - accuracy: 0.8373 - val_loss: 0.3580 - val_accuracy: 0.8475\n",
      "Epoch 31/50\n",
      "121/121 [==============================] - 3s 25ms/step - loss: 0.3613 - accuracy: 0.8365 - val_loss: 0.3653 - val_accuracy: 0.8392\n",
      "Epoch 32/50\n",
      "121/121 [==============================] - 3s 24ms/step - loss: 0.3609 - accuracy: 0.8380 - val_loss: 0.3477 - val_accuracy: 0.8537\n",
      "Epoch 33/50\n",
      "121/121 [==============================] - 3s 25ms/step - loss: 0.3559 - accuracy: 0.8443 - val_loss: 0.3618 - val_accuracy: 0.8402\n",
      "Epoch 34/50\n",
      "121/121 [==============================] - 3s 24ms/step - loss: 0.3500 - accuracy: 0.8474 - val_loss: 0.3590 - val_accuracy: 0.8434\n",
      "Epoch 35/50\n",
      "121/121 [==============================] - 3s 25ms/step - loss: 0.3525 - accuracy: 0.8443 - val_loss: 0.3557 - val_accuracy: 0.8444\n",
      "Epoch 36/50\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 0.3569 - accuracy: 0.8453 - val_loss: 0.3573 - val_accuracy: 0.8392\n",
      "Epoch 37/50\n",
      "121/121 [==============================] - 3s 27ms/step - loss: 0.3466 - accuracy: 0.8492 - val_loss: 0.3559 - val_accuracy: 0.8506\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3058 - accuracy: 0.8747\n",
      "Test Loss: 0.30578163266181946\n",
      "Test Accuracy: 0.8746888041496277\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_features, target, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "X_val = np.reshape(X_val, (X_val.shape[0], X_val.shape[1], 1))\n",
    "\n",
    "\n",
    "# the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.2))  # layer for regularization\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.2))  # layer for regularization\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compiling the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# validation mechanism\n",
    "early_stopping = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train \n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "\n",
    "#testing\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0333a1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "57c30d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "Prediction: Congestion chances: [[0.9856606]]\n"
     ]
    }
   ],
   "source": [
    "data_point = np.array([[5520,80,-3.674076,\t40.480649,21,0,11,9]])  # Replace ... with your data\n",
    "\n",
    "# Scale and reshape the data point\n",
    "# scaled_data_point = scaler.transform(data_point)\n",
    "# reshaped_data_point = np.reshape(scaled_data_point, (1, 1, scaled_data_point.shape[1]))\n",
    "\n",
    "# # Predict using the trained model\n",
    "# prediction = model.predict(reshaped_data_point)\n",
    "\n",
    "scaled_data_point = scaler.transform(data_point)\n",
    "reshaped_data_point = np.reshape(scaled_data_point, (1,scaled_data_point.shape[1],1))\n",
    "\n",
    "# Predict using the trained model\n",
    "prediction = model.predict(reshaped_data_point)\n",
    "# Convert the prediction to congestion or not\n",
    "if prediction > 0.5:\n",
    "    congestion = f\"Congestion chances: {prediction}\"\n",
    "else:\n",
    "    congestion = f\"No Congestion {prediction}\"\n",
    "\n",
    "# Print the prediction\n",
    "print(\"Prediction:\", congestion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "67113812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hihihihi\n",
      "Epoch 1/50\n",
      "121/121 [==============================] - 25s 98ms/step - loss: 0.6501 - accuracy: 0.6512 - val_loss: 0.6266 - val_accuracy: 0.6805\n",
      "Epoch 2/50\n",
      "121/121 [==============================] - 9s 74ms/step - loss: 0.6474 - accuracy: 0.6520 - val_loss: 0.6287 - val_accuracy: 0.6805\n",
      "Epoch 3/50\n",
      "121/121 [==============================] - 9s 74ms/step - loss: 0.6444 - accuracy: 0.6520 - val_loss: 0.6216 - val_accuracy: 0.6805\n",
      "Epoch 4/50\n",
      "121/121 [==============================] - 9s 75ms/step - loss: 0.6283 - accuracy: 0.6520 - val_loss: 0.5752 - val_accuracy: 0.7012\n",
      "Epoch 5/50\n",
      "121/121 [==============================] - 9s 74ms/step - loss: 0.5489 - accuracy: 0.7145 - val_loss: 0.5010 - val_accuracy: 0.7365\n",
      "Epoch 6/50\n",
      "121/121 [==============================] - 9s 76ms/step - loss: 0.4693 - accuracy: 0.7669 - val_loss: 0.4081 - val_accuracy: 0.8029\n",
      "Epoch 7/50\n",
      "121/121 [==============================] - 9s 75ms/step - loss: 0.4554 - accuracy: 0.7742 - val_loss: 0.3987 - val_accuracy: 0.8081\n",
      "Epoch 8/50\n",
      "121/121 [==============================] - 9s 75ms/step - loss: 0.4539 - accuracy: 0.7706 - val_loss: 0.4240 - val_accuracy: 0.7822\n",
      "Epoch 9/50\n",
      "121/121 [==============================] - 9s 75ms/step - loss: 0.4349 - accuracy: 0.7822 - val_loss: 0.4136 - val_accuracy: 0.8019\n",
      "Epoch 10/50\n",
      "121/121 [==============================] - 9s 74ms/step - loss: 0.4231 - accuracy: 0.7934 - val_loss: 0.3887 - val_accuracy: 0.8299\n",
      "Epoch 11/50\n",
      "121/121 [==============================] - 9s 73ms/step - loss: 0.4177 - accuracy: 0.8043 - val_loss: 0.3878 - val_accuracy: 0.8423\n",
      "Epoch 12/50\n",
      "121/121 [==============================] - 9s 74ms/step - loss: 0.4104 - accuracy: 0.8103 - val_loss: 0.4126 - val_accuracy: 0.8019\n",
      "Epoch 13/50\n",
      "121/121 [==============================] - 9s 75ms/step - loss: 0.4103 - accuracy: 0.8066 - val_loss: 0.3818 - val_accuracy: 0.8361\n",
      "Epoch 14/50\n",
      "121/121 [==============================] - 9s 74ms/step - loss: 0.4011 - accuracy: 0.8144 - val_loss: 0.3809 - val_accuracy: 0.8475\n",
      "Epoch 15/50\n",
      "121/121 [==============================] - 9s 75ms/step - loss: 0.4008 - accuracy: 0.8142 - val_loss: 0.3694 - val_accuracy: 0.8434\n",
      "Epoch 16/50\n",
      "121/121 [==============================] - 9s 76ms/step - loss: 0.4024 - accuracy: 0.8152 - val_loss: 0.4202 - val_accuracy: 0.7894\n",
      "Epoch 17/50\n",
      "121/121 [==============================] - 9s 74ms/step - loss: 0.4045 - accuracy: 0.8196 - val_loss: 0.3732 - val_accuracy: 0.8402\n",
      "Epoch 18/50\n",
      "121/121 [==============================] - 9s 73ms/step - loss: 0.3894 - accuracy: 0.8251 - val_loss: 0.3711 - val_accuracy: 0.8402\n",
      "Epoch 19/50\n",
      "121/121 [==============================] - 9s 73ms/step - loss: 0.3848 - accuracy: 0.8274 - val_loss: 0.3757 - val_accuracy: 0.8320\n",
      "Epoch 20/50\n",
      "121/121 [==============================] - 9s 75ms/step - loss: 0.3810 - accuracy: 0.8246 - val_loss: 0.3721 - val_accuracy: 0.8465\n",
      "38/38 [==============================] - 1s 26ms/step - loss: 0.3312 - accuracy: 0.8622\n",
      "Test Loss: 0.3312376141548157\n",
      "Test Accuracy: 0.8622406721115112\n",
      "hihihihi\n",
      "Epoch 1/50\n",
      "121/121 [==============================] - 24s 92ms/step - loss: 0.6549 - accuracy: 0.6499 - val_loss: 0.6276 - val_accuracy: 0.6805\n",
      "Epoch 2/50\n",
      "121/121 [==============================] - 8s 69ms/step - loss: 0.6475 - accuracy: 0.6520 - val_loss: 0.6355 - val_accuracy: 0.6805\n",
      "Epoch 3/50\n",
      "121/121 [==============================] - 8s 68ms/step - loss: 0.6477 - accuracy: 0.6520 - val_loss: 0.6253 - val_accuracy: 0.6805\n",
      "Epoch 4/50\n",
      "121/121 [==============================] - 9s 72ms/step - loss: 0.6443 - accuracy: 0.6520 - val_loss: 0.6120 - val_accuracy: 0.6805\n",
      "Epoch 5/50\n",
      "121/121 [==============================] - 7s 60ms/step - loss: 0.6199 - accuracy: 0.6530 - val_loss: 0.5673 - val_accuracy: 0.6836\n",
      "Epoch 6/50\n",
      "121/121 [==============================] - 7s 58ms/step - loss: 0.5494 - accuracy: 0.7041 - val_loss: 0.5024 - val_accuracy: 0.7448\n",
      "Epoch 7/50\n",
      "121/121 [==============================] - 7s 59ms/step - loss: 0.4931 - accuracy: 0.7581 - val_loss: 0.4539 - val_accuracy: 0.7853\n",
      "Epoch 8/50\n",
      "121/121 [==============================] - 7s 59ms/step - loss: 0.4694 - accuracy: 0.7612 - val_loss: 0.4229 - val_accuracy: 0.7946\n",
      "Epoch 9/50\n",
      "121/121 [==============================] - 8s 69ms/step - loss: 0.4504 - accuracy: 0.7745 - val_loss: 0.4118 - val_accuracy: 0.7925\n",
      "Epoch 10/50\n",
      "121/121 [==============================] - 7s 62ms/step - loss: 0.4379 - accuracy: 0.7822 - val_loss: 0.4083 - val_accuracy: 0.7967\n",
      "Epoch 11/50\n",
      "121/121 [==============================] - 8s 67ms/step - loss: 0.4348 - accuracy: 0.7874 - val_loss: 0.4626 - val_accuracy: 0.7635\n",
      "Epoch 12/50\n",
      "121/121 [==============================] - 8s 68ms/step - loss: 0.4338 - accuracy: 0.7874 - val_loss: 0.4083 - val_accuracy: 0.8102\n",
      "Epoch 13/50\n",
      "121/121 [==============================] - 8s 70ms/step - loss: 0.4206 - accuracy: 0.7976 - val_loss: 0.3972 - val_accuracy: 0.8216\n",
      "Epoch 14/50\n",
      "121/121 [==============================] - 8s 69ms/step - loss: 0.4051 - accuracy: 0.8090 - val_loss: 0.3753 - val_accuracy: 0.8371\n",
      "Epoch 15/50\n",
      "121/121 [==============================] - 8s 70ms/step - loss: 0.4085 - accuracy: 0.8103 - val_loss: 0.3859 - val_accuracy: 0.8340\n",
      "Epoch 16/50\n",
      "121/121 [==============================] - 8s 69ms/step - loss: 0.4024 - accuracy: 0.8079 - val_loss: 0.3855 - val_accuracy: 0.8288\n",
      "Epoch 17/50\n",
      "121/121 [==============================] - 8s 69ms/step - loss: 0.4106 - accuracy: 0.8033 - val_loss: 0.3946 - val_accuracy: 0.8133\n",
      "Epoch 18/50\n",
      "121/121 [==============================] - 8s 69ms/step - loss: 0.3933 - accuracy: 0.8225 - val_loss: 0.3752 - val_accuracy: 0.8465\n",
      "Epoch 19/50\n",
      "121/121 [==============================] - 8s 68ms/step - loss: 0.3880 - accuracy: 0.8238 - val_loss: 0.3702 - val_accuracy: 0.8454\n",
      "Epoch 20/50\n",
      "121/121 [==============================] - 8s 70ms/step - loss: 0.3803 - accuracy: 0.8323 - val_loss: 0.3636 - val_accuracy: 0.8475\n",
      "Epoch 21/50\n",
      "121/121 [==============================] - 8s 69ms/step - loss: 0.3853 - accuracy: 0.8261 - val_loss: 0.4106 - val_accuracy: 0.8081\n",
      "Epoch 22/50\n",
      "121/121 [==============================] - 8s 69ms/step - loss: 0.3738 - accuracy: 0.8344 - val_loss: 0.3607 - val_accuracy: 0.8506\n",
      "Epoch 23/50\n",
      "121/121 [==============================] - 8s 69ms/step - loss: 0.3732 - accuracy: 0.8383 - val_loss: 0.3613 - val_accuracy: 0.8475\n",
      "Epoch 24/50\n",
      "121/121 [==============================] - 8s 69ms/step - loss: 0.3748 - accuracy: 0.8287 - val_loss: 0.3661 - val_accuracy: 0.8485\n",
      "Epoch 25/50\n",
      "121/121 [==============================] - 8s 69ms/step - loss: 0.3695 - accuracy: 0.8373 - val_loss: 0.3619 - val_accuracy: 0.8485\n",
      "Epoch 26/50\n",
      "121/121 [==============================] - 8s 69ms/step - loss: 0.3602 - accuracy: 0.8451 - val_loss: 0.3493 - val_accuracy: 0.8558\n",
      "Epoch 27/50\n",
      "121/121 [==============================] - 9s 73ms/step - loss: 0.3678 - accuracy: 0.8342 - val_loss: 0.3768 - val_accuracy: 0.8320\n",
      "Epoch 28/50\n",
      "121/121 [==============================] - 8s 63ms/step - loss: 0.3604 - accuracy: 0.8383 - val_loss: 0.3829 - val_accuracy: 0.8340\n",
      "Epoch 29/50\n",
      "121/121 [==============================] - 7s 60ms/step - loss: 0.3648 - accuracy: 0.8396 - val_loss: 0.3624 - val_accuracy: 0.8517\n",
      "Epoch 30/50\n",
      "121/121 [==============================] - 8s 63ms/step - loss: 0.3579 - accuracy: 0.8458 - val_loss: 0.3493 - val_accuracy: 0.8568\n",
      "Epoch 31/50\n",
      "121/121 [==============================] - 8s 62ms/step - loss: 0.3518 - accuracy: 0.8508 - val_loss: 0.3674 - val_accuracy: 0.8485\n",
      "38/38 [==============================] - 1s 19ms/step - loss: 0.3012 - accuracy: 0.8797\n",
      "Test Loss: 0.30122172832489014\n",
      "Test Accuracy: 0.8796680569648743\n",
      "Epoch 1/50\n",
      "121/121 [==============================] - 27s 103ms/step - loss: 0.6501 - accuracy: 0.6517 - val_loss: 0.6295 - val_accuracy: 0.6805\n",
      "Epoch 2/50\n",
      "121/121 [==============================] - 10s 81ms/step - loss: 0.6490 - accuracy: 0.6520 - val_loss: 0.6325 - val_accuracy: 0.6805\n",
      "Epoch 3/50\n",
      "121/121 [==============================] - 10s 81ms/step - loss: 0.6474 - accuracy: 0.6520 - val_loss: 0.6260 - val_accuracy: 0.6805\n",
      "Epoch 4/50\n",
      "121/121 [==============================] - 10s 79ms/step - loss: 0.6448 - accuracy: 0.6520 - val_loss: 0.6159 - val_accuracy: 0.6805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50\n",
      "121/121 [==============================] - 9s 77ms/step - loss: 0.6009 - accuracy: 0.6717 - val_loss: 0.5030 - val_accuracy: 0.7552\n",
      "Epoch 6/50\n",
      "121/121 [==============================] - 9s 77ms/step - loss: 0.5225 - accuracy: 0.7236 - val_loss: 0.5139 - val_accuracy: 0.7614\n",
      "Epoch 7/50\n",
      "121/121 [==============================] - 9s 78ms/step - loss: 0.4941 - accuracy: 0.7472 - val_loss: 0.4700 - val_accuracy: 0.7936\n",
      "Epoch 8/50\n",
      "121/121 [==============================] - 9s 78ms/step - loss: 0.4661 - accuracy: 0.7677 - val_loss: 0.4393 - val_accuracy: 0.7842\n",
      "Epoch 9/50\n",
      "121/121 [==============================] - 10s 79ms/step - loss: 0.4563 - accuracy: 0.7677 - val_loss: 0.4209 - val_accuracy: 0.7801\n",
      "Epoch 10/50\n",
      "121/121 [==============================] - 9s 77ms/step - loss: 0.4480 - accuracy: 0.7771 - val_loss: 0.4052 - val_accuracy: 0.8102\n",
      "Epoch 11/50\n",
      "121/121 [==============================] - 10s 83ms/step - loss: 0.4442 - accuracy: 0.7835 - val_loss: 0.4070 - val_accuracy: 0.8112\n",
      "Epoch 12/50\n",
      "121/121 [==============================] - 10s 83ms/step - loss: 0.4415 - accuracy: 0.7895 - val_loss: 0.4008 - val_accuracy: 0.8154\n",
      "Epoch 13/50\n",
      "121/121 [==============================] - 10s 79ms/step - loss: 0.4245 - accuracy: 0.7934 - val_loss: 0.4079 - val_accuracy: 0.7967\n",
      "Epoch 14/50\n",
      "121/121 [==============================] - 10s 79ms/step - loss: 0.4202 - accuracy: 0.7931 - val_loss: 0.4166 - val_accuracy: 0.8050\n",
      "Epoch 15/50\n",
      "121/121 [==============================] - 12s 97ms/step - loss: 0.4098 - accuracy: 0.8113 - val_loss: 0.3779 - val_accuracy: 0.8392\n",
      "Epoch 16/50\n",
      "121/121 [==============================] - 11s 90ms/step - loss: 0.4072 - accuracy: 0.8188 - val_loss: 0.3800 - val_accuracy: 0.8402\n",
      "Epoch 17/50\n",
      "121/121 [==============================] - 10s 81ms/step - loss: 0.4089 - accuracy: 0.8074 - val_loss: 0.3706 - val_accuracy: 0.8423\n",
      "Epoch 18/50\n",
      "121/121 [==============================] - 13s 105ms/step - loss: 0.3871 - accuracy: 0.8287 - val_loss: 0.4218 - val_accuracy: 0.8050\n",
      "Epoch 19/50\n",
      "121/121 [==============================] - 15s 124ms/step - loss: 0.3965 - accuracy: 0.8225 - val_loss: 0.3834 - val_accuracy: 0.8340\n",
      "Epoch 20/50\n",
      "121/121 [==============================] - 13s 112ms/step - loss: 0.3934 - accuracy: 0.8264 - val_loss: 0.3596 - val_accuracy: 0.8465\n",
      "Epoch 21/50\n",
      "121/121 [==============================] - 12s 101ms/step - loss: 0.3779 - accuracy: 0.8287 - val_loss: 0.3696 - val_accuracy: 0.8537\n",
      "Epoch 22/50\n",
      "121/121 [==============================] - 10s 85ms/step - loss: 0.3813 - accuracy: 0.8292 - val_loss: 0.3679 - val_accuracy: 0.8579\n",
      "Epoch 23/50\n",
      "121/121 [==============================] - 11s 88ms/step - loss: 0.3766 - accuracy: 0.8303 - val_loss: 0.3489 - val_accuracy: 0.8579\n",
      "Epoch 24/50\n",
      "121/121 [==============================] - 9s 78ms/step - loss: 0.3654 - accuracy: 0.8406 - val_loss: 0.3576 - val_accuracy: 0.8527\n",
      "Epoch 25/50\n",
      "121/121 [==============================] - 9s 74ms/step - loss: 0.3681 - accuracy: 0.8380 - val_loss: 0.3801 - val_accuracy: 0.8309\n",
      "Epoch 26/50\n",
      "121/121 [==============================] - 8s 69ms/step - loss: 0.3627 - accuracy: 0.8417 - val_loss: 0.3519 - val_accuracy: 0.8517\n",
      "Epoch 27/50\n",
      "121/121 [==============================] - 9s 72ms/step - loss: 0.3651 - accuracy: 0.8344 - val_loss: 0.3787 - val_accuracy: 0.8444\n",
      "Epoch 28/50\n",
      "121/121 [==============================] - 10s 79ms/step - loss: 0.3721 - accuracy: 0.8396 - val_loss: 0.3514 - val_accuracy: 0.8485\n",
      "38/38 [==============================] - 1s 26ms/step - loss: 0.3147 - accuracy: 0.8722\n",
      "Test Loss: 0.3146699070930481\n",
      "Test Accuracy: 0.8721991777420044\n",
      "5 min passed!\n",
      "hihihihi\n",
      "Epoch 1/50\n",
      "121/121 [==============================] - 25s 96ms/step - loss: 0.6526 - accuracy: 0.6491 - val_loss: 0.6375 - val_accuracy: 0.6805\n",
      "Epoch 2/50\n",
      "121/121 [==============================] - 9s 73ms/step - loss: 0.6482 - accuracy: 0.6520 - val_loss: 0.6437 - val_accuracy: 0.6805\n",
      "Epoch 3/50\n",
      "121/121 [==============================] - 9s 73ms/step - loss: 0.6469 - accuracy: 0.6520 - val_loss: 0.6204 - val_accuracy: 0.6805\n",
      "Epoch 4/50\n",
      "121/121 [==============================] - 9s 73ms/step - loss: 0.6282 - accuracy: 0.6507 - val_loss: 0.5808 - val_accuracy: 0.6815\n",
      "Epoch 5/50\n",
      "121/121 [==============================] - 9s 73ms/step - loss: 0.5856 - accuracy: 0.6779 - val_loss: 0.5031 - val_accuracy: 0.7396\n",
      "Epoch 6/50\n",
      "121/121 [==============================] - 9s 73ms/step - loss: 0.4990 - accuracy: 0.7451 - val_loss: 0.4385 - val_accuracy: 0.7853\n",
      "Epoch 7/50\n",
      "121/121 [==============================] - 9s 74ms/step - loss: 0.4675 - accuracy: 0.7688 - val_loss: 0.4478 - val_accuracy: 0.7593\n",
      "Epoch 8/50\n",
      "121/121 [==============================] - 9s 75ms/step - loss: 0.4504 - accuracy: 0.7828 - val_loss: 0.3957 - val_accuracy: 0.8133\n",
      "Epoch 9/50\n",
      "121/121 [==============================] - 9s 74ms/step - loss: 0.4257 - accuracy: 0.7895 - val_loss: 0.4001 - val_accuracy: 0.7967\n",
      "Epoch 10/50\n",
      "121/121 [==============================] - 9s 73ms/step - loss: 0.4393 - accuracy: 0.7926 - val_loss: 0.3877 - val_accuracy: 0.8320\n",
      "Epoch 11/50\n",
      "121/121 [==============================] - 9s 73ms/step - loss: 0.4116 - accuracy: 0.8066 - val_loss: 0.3803 - val_accuracy: 0.8237\n",
      "Epoch 12/50\n",
      "121/121 [==============================] - 9s 73ms/step - loss: 0.4205 - accuracy: 0.7999 - val_loss: 0.3821 - val_accuracy: 0.8382\n",
      "Epoch 13/50\n",
      "121/121 [==============================] - 9s 73ms/step - loss: 0.4046 - accuracy: 0.8131 - val_loss: 0.4417 - val_accuracy: 0.7759\n",
      "Epoch 14/50\n",
      "121/121 [==============================] - 9s 75ms/step - loss: 0.4062 - accuracy: 0.8074 - val_loss: 0.3900 - val_accuracy: 0.8174\n",
      "Epoch 15/50\n",
      "121/121 [==============================] - 9s 74ms/step - loss: 0.4046 - accuracy: 0.8116 - val_loss: 0.3776 - val_accuracy: 0.8330\n",
      "Epoch 16/50\n",
      "121/121 [==============================] - 9s 74ms/step - loss: 0.3994 - accuracy: 0.8217 - val_loss: 0.3899 - val_accuracy: 0.8164\n",
      "Epoch 17/50\n",
      "121/121 [==============================] - 9s 74ms/step - loss: 0.3985 - accuracy: 0.8204 - val_loss: 0.3749 - val_accuracy: 0.8278\n",
      "Epoch 18/50\n",
      "121/121 [==============================] - 9s 74ms/step - loss: 0.3939 - accuracy: 0.8256 - val_loss: 0.3663 - val_accuracy: 0.8454\n",
      "Epoch 19/50\n",
      "121/121 [==============================] - 9s 73ms/step - loss: 0.3843 - accuracy: 0.8303 - val_loss: 0.3575 - val_accuracy: 0.8579\n",
      "Epoch 20/50\n",
      "121/121 [==============================] - 9s 74ms/step - loss: 0.3756 - accuracy: 0.8352 - val_loss: 0.3499 - val_accuracy: 0.8548\n",
      "Epoch 21/50\n",
      "121/121 [==============================] - 9s 74ms/step - loss: 0.3757 - accuracy: 0.8331 - val_loss: 0.3650 - val_accuracy: 0.8351\n",
      "Epoch 22/50\n",
      "121/121 [==============================] - 9s 75ms/step - loss: 0.3705 - accuracy: 0.8380 - val_loss: 0.3511 - val_accuracy: 0.8568\n",
      "Epoch 23/50\n",
      "121/121 [==============================] - 9s 77ms/step - loss: 0.3715 - accuracy: 0.8365 - val_loss: 0.3544 - val_accuracy: 0.8527\n",
      "Epoch 24/50\n",
      "121/121 [==============================] - 9s 76ms/step - loss: 0.3784 - accuracy: 0.8297 - val_loss: 0.3854 - val_accuracy: 0.8309\n",
      "Epoch 25/50\n",
      "121/121 [==============================] - 9s 74ms/step - loss: 0.3720 - accuracy: 0.8331 - val_loss: 0.3816 - val_accuracy: 0.8288\n",
      "38/38 [==============================] - 1s 23ms/step - loss: 0.2998 - accuracy: 0.8855\n",
      "Test Loss: 0.2998107969760895\n",
      "Test Accuracy: 0.8854771852493286\n",
      "hihihihi\n",
      "Epoch 1/50\n",
      "121/121 [==============================] - 26s 110ms/step - loss: 0.6524 - accuracy: 0.6509 - val_loss: 0.6345 - val_accuracy: 0.6805\n",
      "Epoch 2/50\n",
      "121/121 [==============================] - 11s 93ms/step - loss: 0.6490 - accuracy: 0.6520 - val_loss: 0.6313 - val_accuracy: 0.6805\n",
      "Epoch 3/50\n",
      "121/121 [==============================] - 10s 86ms/step - loss: 0.6444 - accuracy: 0.6520 - val_loss: 0.6141 - val_accuracy: 0.6805\n",
      "Epoch 4/50\n",
      "121/121 [==============================] - 11s 90ms/step - loss: 0.6317 - accuracy: 0.6488 - val_loss: 0.5791 - val_accuracy: 0.6909\n",
      "Epoch 5/50\n",
      "121/121 [==============================] - 11s 91ms/step - loss: 0.5590 - accuracy: 0.7078 - val_loss: 0.4704 - val_accuracy: 0.7614\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121/121 [==============================] - 11s 94ms/step - loss: 0.4988 - accuracy: 0.7431 - val_loss: 0.5021 - val_accuracy: 0.7479\n",
      "Epoch 7/50\n",
      "121/121 [==============================] - 11s 95ms/step - loss: 0.4711 - accuracy: 0.7542 - val_loss: 0.4436 - val_accuracy: 0.7718\n",
      "Epoch 8/50\n",
      "121/121 [==============================] - 12s 95ms/step - loss: 0.4514 - accuracy: 0.7693 - val_loss: 0.4173 - val_accuracy: 0.8071\n",
      "Epoch 9/50\n",
      "121/121 [==============================] - 12s 97ms/step - loss: 0.4426 - accuracy: 0.7825 - val_loss: 0.4718 - val_accuracy: 0.7614\n",
      "Epoch 10/50\n",
      "121/121 [==============================] - 11s 93ms/step - loss: 0.4304 - accuracy: 0.7900 - val_loss: 0.4140 - val_accuracy: 0.8112\n",
      "Epoch 11/50\n",
      "121/121 [==============================] - 11s 94ms/step - loss: 0.4264 - accuracy: 0.7942 - val_loss: 0.4044 - val_accuracy: 0.8019\n",
      "Epoch 12/50\n",
      "121/121 [==============================] - 11s 94ms/step - loss: 0.4239 - accuracy: 0.7944 - val_loss: 0.4047 - val_accuracy: 0.7967\n",
      "Epoch 13/50\n",
      "121/121 [==============================] - 12s 100ms/step - loss: 0.4099 - accuracy: 0.8064 - val_loss: 0.3967 - val_accuracy: 0.8164\n",
      "Epoch 14/50\n",
      "121/121 [==============================] - 11s 94ms/step - loss: 0.4166 - accuracy: 0.7986 - val_loss: 0.3844 - val_accuracy: 0.8288\n",
      "Epoch 15/50\n",
      "121/121 [==============================] - 11s 94ms/step - loss: 0.4030 - accuracy: 0.8165 - val_loss: 0.3722 - val_accuracy: 0.8413\n",
      "Epoch 16/50\n",
      "121/121 [==============================] - 12s 96ms/step - loss: 0.3946 - accuracy: 0.8230 - val_loss: 0.3894 - val_accuracy: 0.8268\n",
      "Epoch 17/50\n",
      "121/121 [==============================] - 13s 106ms/step - loss: 0.3867 - accuracy: 0.8274 - val_loss: 0.4514 - val_accuracy: 0.7842\n",
      "Epoch 18/50\n",
      "121/121 [==============================] - 12s 97ms/step - loss: 0.3919 - accuracy: 0.8227 - val_loss: 0.3797 - val_accuracy: 0.8278\n",
      "Epoch 19/50\n",
      "121/121 [==============================] - 12s 95ms/step - loss: 0.3911 - accuracy: 0.8261 - val_loss: 0.3655 - val_accuracy: 0.8465\n",
      "Epoch 20/50\n",
      "121/121 [==============================] - 11s 94ms/step - loss: 0.3836 - accuracy: 0.8310 - val_loss: 0.3711 - val_accuracy: 0.8444\n",
      "Epoch 21/50\n",
      "121/121 [==============================] - 12s 100ms/step - loss: 0.3792 - accuracy: 0.8305 - val_loss: 0.3849 - val_accuracy: 0.8309\n",
      "Epoch 22/50\n",
      "121/121 [==============================] - 12s 95ms/step - loss: 0.3805 - accuracy: 0.8287 - val_loss: 0.3723 - val_accuracy: 0.8434\n",
      "Epoch 23/50\n",
      "121/121 [==============================] - 11s 95ms/step - loss: 0.3748 - accuracy: 0.8323 - val_loss: 0.3671 - val_accuracy: 0.8340\n",
      "Epoch 24/50\n",
      "121/121 [==============================] - 12s 95ms/step - loss: 0.3757 - accuracy: 0.8321 - val_loss: 0.3728 - val_accuracy: 0.8361\n",
      "38/38 [==============================] - 1s 25ms/step - loss: 0.3265 - accuracy: 0.8697\n",
      "Test Loss: 0.3265100121498108\n",
      "Test Accuracy: 0.8697095513343811\n",
      "Epoch 1/50\n",
      "121/121 [==============================] - 30s 147ms/step - loss: 0.6522 - accuracy: 0.6483 - val_loss: 0.6405 - val_accuracy: 0.6805\n",
      "Epoch 2/50\n",
      "121/121 [==============================] - 15s 121ms/step - loss: 0.6484 - accuracy: 0.6520 - val_loss: 0.6281 - val_accuracy: 0.6805\n",
      "Epoch 3/50\n",
      "121/121 [==============================] - 13s 110ms/step - loss: 0.6463 - accuracy: 0.6520 - val_loss: 0.6226 - val_accuracy: 0.6805\n",
      "Epoch 4/50\n",
      "121/121 [==============================] - 13s 107ms/step - loss: 0.6368 - accuracy: 0.6527 - val_loss: 0.6033 - val_accuracy: 0.6857\n",
      "Epoch 5/50\n",
      "121/121 [==============================] - 13s 108ms/step - loss: 0.5899 - accuracy: 0.6709 - val_loss: 0.5344 - val_accuracy: 0.7064\n",
      "Epoch 6/50\n",
      "121/121 [==============================] - 13s 107ms/step - loss: 0.5164 - accuracy: 0.7342 - val_loss: 0.4464 - val_accuracy: 0.7801\n",
      "Epoch 7/50\n",
      "121/121 [==============================] - 13s 108ms/step - loss: 0.4848 - accuracy: 0.7617 - val_loss: 0.4287 - val_accuracy: 0.7915\n",
      "Epoch 8/50\n",
      "121/121 [==============================] - 13s 107ms/step - loss: 0.4447 - accuracy: 0.7799 - val_loss: 0.3977 - val_accuracy: 0.8216\n",
      "Epoch 9/50\n",
      "121/121 [==============================] - 12s 100ms/step - loss: 0.4398 - accuracy: 0.7781 - val_loss: 0.3970 - val_accuracy: 0.8071\n",
      "Epoch 10/50\n",
      "121/121 [==============================] - 12s 100ms/step - loss: 0.4255 - accuracy: 0.7869 - val_loss: 0.3898 - val_accuracy: 0.8371\n",
      "Epoch 11/50\n",
      "121/121 [==============================] - 13s 107ms/step - loss: 0.4209 - accuracy: 0.7978 - val_loss: 0.3857 - val_accuracy: 0.8237\n",
      "Epoch 12/50\n",
      "121/121 [==============================] - 13s 106ms/step - loss: 0.4141 - accuracy: 0.8028 - val_loss: 0.3832 - val_accuracy: 0.8299\n",
      "Epoch 13/50\n",
      "121/121 [==============================] - 13s 107ms/step - loss: 0.4091 - accuracy: 0.8118 - val_loss: 0.3759 - val_accuracy: 0.8351\n",
      "Epoch 14/50\n",
      "121/121 [==============================] - 13s 108ms/step - loss: 0.3975 - accuracy: 0.8230 - val_loss: 0.3649 - val_accuracy: 0.8558\n",
      "Epoch 15/50\n",
      "121/121 [==============================] - 13s 107ms/step - loss: 0.4017 - accuracy: 0.8137 - val_loss: 0.3659 - val_accuracy: 0.8475\n",
      "Epoch 16/50\n",
      "121/121 [==============================] - 13s 107ms/step - loss: 0.3881 - accuracy: 0.8313 - val_loss: 0.3671 - val_accuracy: 0.8444\n",
      "Epoch 17/50\n",
      "121/121 [==============================] - 13s 107ms/step - loss: 0.3846 - accuracy: 0.8271 - val_loss: 0.4061 - val_accuracy: 0.8195\n",
      "Epoch 18/50\n",
      "121/121 [==============================] - 13s 107ms/step - loss: 0.3892 - accuracy: 0.8253 - val_loss: 0.3644 - val_accuracy: 0.8496\n",
      "Epoch 19/50\n",
      "121/121 [==============================] - 6917s 58s/step - loss: 0.3869 - accuracy: 0.8300 - val_loss: 0.3824 - val_accuracy: 0.8340\n",
      "Epoch 20/50\n",
      "121/121 [==============================] - 65s 544ms/step - loss: 0.3763 - accuracy: 0.8373 - val_loss: 0.3537 - val_accuracy: 0.8537\n",
      "Epoch 21/50\n",
      "121/121 [==============================] - 13s 107ms/step - loss: 0.3640 - accuracy: 0.8458 - val_loss: 0.3574 - val_accuracy: 0.8506\n",
      "Epoch 22/50\n",
      "121/121 [==============================] - 421s 4s/step - loss: 0.3684 - accuracy: 0.8422 - val_loss: 0.3555 - val_accuracy: 0.8517\n",
      "Epoch 23/50\n",
      "121/121 [==============================] - 281s 2s/step - loss: 0.3663 - accuracy: 0.8386 - val_loss: 0.3868 - val_accuracy: 0.8205\n",
      "Epoch 24/50\n",
      "121/121 [==============================] - 10901s 91s/step - loss: 0.3793 - accuracy: 0.8261 - val_loss: 0.3672 - val_accuracy: 0.8434\n",
      "Epoch 25/50\n",
      "121/121 [==============================] - 218371s 1820s/step - loss: 0.3750 - accuracy: 0.8336 - val_loss: 0.3702 - val_accuracy: 0.8465\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 0.3059 - accuracy: 0.8772\n",
      "Test Loss: 0.3058689832687378\n",
      "Test Accuracy: 0.877178430557251\n",
      "5 min passed!\n",
      "hihihihi\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function UniquePtr.__del__ at 0x000001D557D9CCA0>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Anup\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\framework\\c_api_util.py\", line 70, in __del__\n",
      "    def __del__(self):\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 57/121 [=============>................] - ETA: 7s - loss: 0.6550 - accuracy: 0.6469"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [60]\u001b[0m, in \u001b[0;36m<cell line: 50>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Run the scheduler indefinitely\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m     \u001b[43mschedule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_pending\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\schedule\\__init__.py:822\u001b[0m, in \u001b[0;36mrun_pending\u001b[1;34m()\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_pending\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    819\u001b[0m     \u001b[38;5;124;03m\"\"\"Calls :meth:`run_pending <Scheduler.run_pending>` on the\u001b[39;00m\n\u001b[0;32m    820\u001b[0m \u001b[38;5;124;03m    :data:`default scheduler instance <default_scheduler>`.\u001b[39;00m\n\u001b[0;32m    821\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 822\u001b[0m     \u001b[43mdefault_scheduler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_pending\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\schedule\\__init__.py:100\u001b[0m, in \u001b[0;36mScheduler.run_pending\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     98\u001b[0m runnable_jobs \u001b[38;5;241m=\u001b[39m (job \u001b[38;5;28;01mfor\u001b[39;00m job \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjobs \u001b[38;5;28;01mif\u001b[39;00m job\u001b[38;5;241m.\u001b[39mshould_run)\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m job \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(runnable_jobs):\n\u001b[1;32m--> 100\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_job\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\schedule\\__init__.py:172\u001b[0m, in \u001b[0;36mScheduler._run_job\u001b[1;34m(self, job)\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_job\u001b[39m(\u001b[38;5;28mself\u001b[39m, job: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJob\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 172\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, CancelJob) \u001b[38;5;129;01mor\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m CancelJob:\n\u001b[0;32m    174\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_job(job)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\schedule\\__init__.py:693\u001b[0m, in \u001b[0;36mJob.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    690\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m CancelJob\n\u001b[0;32m    692\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning job \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 693\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjob_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    694\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_run \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[0;32m    695\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_schedule_next_run()\n",
      "Input \u001b[1;32mIn [59]\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m     37\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 38\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[0;32m     41\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1677\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1678\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1679\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1682\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1683\u001b[0m ):\n\u001b[0;32m   1684\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1685\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1687\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    891\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 894\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    896\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    897\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    923\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    924\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    925\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 926\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    927\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    928\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    929\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    930\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    141\u001b[0m   (concrete_function,\n\u001b[0;32m    142\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1753\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1755\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1756\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1757\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1758\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1759\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1760\u001b[0m     args,\n\u001b[0;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1762\u001b[0m     executing_eagerly)\n\u001b[0;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    380\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 381\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    387\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    388\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    389\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    390\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    393\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    394\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# pip install schedule\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "import schedule\n",
    "import time\n",
    "\n",
    "# Define your data and model\n",
    "# ...\n",
    "\n",
    "# Define a function to train the model\n",
    "def train_model():\n",
    "    # Data preprocessing\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_features = scaler.fit_transform(features)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(scaled_features, target, test_size=0.2, random_state=42)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "    X_val = np.reshape(X_val, (X_val.shape[0], X_val.shape[1], 1))\n",
    "\n",
    "    # Create the LSTM model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True))\n",
    "    model.add(LSTM(128, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(128))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    early_stopping = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "    history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "\n",
    "    # Evaluate the model\n",
    "    loss, accuracy = model.evaluate(X_test, y_test)\n",
    "    print(\"Test Loss:\", loss)\n",
    "    print(\"Test Accuracy:\", accuracy)\n",
    "    print(\"5 min passed!\")\n",
    "\n",
    "# Define the schedule to train the model every 5 minutes\n",
    "schedule.every(5).minutes.do(train_model)\n",
    "\n",
    "# Run the scheduler indefinitely\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "187afdeb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ExecutableNotFound",
     "evalue": "failed to execute WindowsPath('dot'), make sure the Graphviz executables are on your systems' PATH",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Anup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphviz\\backend\\execute.py:81\u001b[0m, in \u001b[0;36mrun_check\u001b[1;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 81\u001b[0m         proc \u001b[39m=\u001b[39m subprocess\u001b[39m.\u001b[39mrun(cmd, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     82\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\Anup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\subprocess.py:501\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    499\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mstderr\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m PIPE\n\u001b[1;32m--> 501\u001b[0m \u001b[39mwith\u001b[39;00m Popen(\u001b[39m*\u001b[39mpopenargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39mas\u001b[39;00m process:\n\u001b[0;32m    502\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Anup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\subprocess.py:969\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize)\u001b[0m\n\u001b[0;32m    966\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mTextIOWrapper(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr,\n\u001b[0;32m    967\u001b[0m                     encoding\u001b[39m=\u001b[39mencoding, errors\u001b[39m=\u001b[39merrors)\n\u001b[1;32m--> 969\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0;32m    970\u001b[0m                         pass_fds, cwd, env,\n\u001b[0;32m    971\u001b[0m                         startupinfo, creationflags, shell,\n\u001b[0;32m    972\u001b[0m                         p2cread, p2cwrite,\n\u001b[0;32m    973\u001b[0m                         c2pread, c2pwrite,\n\u001b[0;32m    974\u001b[0m                         errread, errwrite,\n\u001b[0;32m    975\u001b[0m                         restore_signals,\n\u001b[0;32m    976\u001b[0m                         gid, gids, uid, umask,\n\u001b[0;32m    977\u001b[0m                         start_new_session)\n\u001b[0;32m    978\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m    979\u001b[0m     \u001b[39m# Cleanup if the child failed starting.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Anup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\subprocess.py:1438\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1438\u001b[0m     hp, ht, pid, tid \u001b[39m=\u001b[39m _winapi\u001b[39m.\u001b[39;49mCreateProcess(executable, args,\n\u001b[0;32m   1439\u001b[0m                              \u001b[39m# no special security\u001b[39;49;00m\n\u001b[0;32m   1440\u001b[0m                              \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m   1441\u001b[0m                              \u001b[39mint\u001b[39;49m(\u001b[39mnot\u001b[39;49;00m close_fds),\n\u001b[0;32m   1442\u001b[0m                              creationflags,\n\u001b[0;32m   1443\u001b[0m                              env,\n\u001b[0;32m   1444\u001b[0m                              cwd,\n\u001b[0;32m   1445\u001b[0m                              startupinfo)\n\u001b[0;32m   1446\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m   1447\u001b[0m     \u001b[39m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1448\u001b[0m     \u001b[39m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1451\u001b[0m     \u001b[39m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1452\u001b[0m     \u001b[39m# ReadFile will hang.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mExecutableNotFound\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32md:\\Evolve-hackathon\\final_model.ipynb Cell 21\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Evolve-hackathon/final_model.ipynb#X26sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m graph\u001b[39m.\u001b[39medge(\u001b[39m\"\u001b[39m\u001b[39mG\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mF\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Evolve-hackathon/final_model.ipynb#X26sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# Render the graph to a file\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Evolve-hackathon/final_model.ipynb#X26sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m graph\u001b[39m.\u001b[39;49mrender(\u001b[39m\"\u001b[39;49m\u001b[39mday_to_day_responsibilities_flowchart\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mformat\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mpng\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Evolve-hackathon/final_model.ipynb#X26sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m c\n",
      "File \u001b[1;32mc:\\Users\\Anup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphviz\\_tools.py:171\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    162\u001b[0m     wanted \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m{\u001b[39;00mvalue\u001b[39m!r}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m    163\u001b[0m                        \u001b[39mfor\u001b[39;00m name, value \u001b[39min\u001b[39;00m deprecated\u001b[39m.\u001b[39mitems())\n\u001b[0;32m    164\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mThe signature of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m will be reduced\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    165\u001b[0m                   \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m to \u001b[39m\u001b[39m{\u001b[39;00msupported_number\u001b[39m}\u001b[39;00m\u001b[39m positional args\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    166\u001b[0m                   \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(supported)\u001b[39m}\u001b[39;00m\u001b[39m: pass \u001b[39m\u001b[39m{\u001b[39;00mwanted\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m    167\u001b[0m                   \u001b[39m'\u001b[39m\u001b[39m as keyword arg(s)\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m    168\u001b[0m                   stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    169\u001b[0m                   category\u001b[39m=\u001b[39mcategory)\n\u001b[1;32m--> 171\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Anup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphviz\\rendering.py:122\u001b[0m, in \u001b[0;36mRender.render\u001b[1;34m(self, filename, directory, view, cleanup, format, renderer, formatter, neato_no_op, quiet, quiet_view, outfile, engine, raise_if_result_exists, overwrite_source)\u001b[0m\n\u001b[0;32m    118\u001b[0m filepath \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave(filename, directory\u001b[39m=\u001b[39mdirectory, skip_existing\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    120\u001b[0m args\u001b[39m.\u001b[39mappend(filepath)\n\u001b[1;32m--> 122\u001b[0m rendered \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_render(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    124\u001b[0m \u001b[39mif\u001b[39;00m cleanup:\n\u001b[0;32m    125\u001b[0m     log\u001b[39m.\u001b[39mdebug(\u001b[39m'\u001b[39m\u001b[39mdelete \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m'\u001b[39m, filepath)\n",
      "File \u001b[1;32mc:\\Users\\Anup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphviz\\_tools.py:171\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    162\u001b[0m     wanted \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m{\u001b[39;00mvalue\u001b[39m!r}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m    163\u001b[0m                        \u001b[39mfor\u001b[39;00m name, value \u001b[39min\u001b[39;00m deprecated\u001b[39m.\u001b[39mitems())\n\u001b[0;32m    164\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mThe signature of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m will be reduced\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    165\u001b[0m                   \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m to \u001b[39m\u001b[39m{\u001b[39;00msupported_number\u001b[39m}\u001b[39;00m\u001b[39m positional args\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    166\u001b[0m                   \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(supported)\u001b[39m}\u001b[39;00m\u001b[39m: pass \u001b[39m\u001b[39m{\u001b[39;00mwanted\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m    167\u001b[0m                   \u001b[39m'\u001b[39m\u001b[39m as keyword arg(s)\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m    168\u001b[0m                   stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    169\u001b[0m                   category\u001b[39m=\u001b[39mcategory)\n\u001b[1;32m--> 171\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Anup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphviz\\backend\\rendering.py:324\u001b[0m, in \u001b[0;36mrender\u001b[1;34m(engine, format, filepath, renderer, formatter, neato_no_op, quiet, outfile, raise_if_result_exists, overwrite_filepath)\u001b[0m\n\u001b[0;32m    320\u001b[0m     \u001b[39mraise\u001b[39;00m exceptions\u001b[39m.\u001b[39mFileExistsError(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39moutput file exists: \u001b[39m\u001b[39m{\u001b[39;00mos\u001b[39m.\u001b[39mfspath(outfile)\u001b[39m!r}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m    322\u001b[0m cmd \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m args\n\u001b[1;32m--> 324\u001b[0m execute\u001b[39m.\u001b[39;49mrun_check(cmd,\n\u001b[0;32m    325\u001b[0m                   cwd\u001b[39m=\u001b[39;49mfilepath\u001b[39m.\u001b[39;49mparent \u001b[39mif\u001b[39;49;00m filepath\u001b[39m.\u001b[39;49mparent\u001b[39m.\u001b[39;49mparts \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    326\u001b[0m                   quiet\u001b[39m=\u001b[39;49mquiet,\n\u001b[0;32m    327\u001b[0m                   capture_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    329\u001b[0m \u001b[39mreturn\u001b[39;00m os\u001b[39m.\u001b[39mfspath(outfile)\n",
      "File \u001b[1;32mc:\\Users\\Anup\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\graphviz\\backend\\execute.py:84\u001b[0m, in \u001b[0;36mrun_check\u001b[1;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     83\u001b[0m     \u001b[39mif\u001b[39;00m e\u001b[39m.\u001b[39merrno \u001b[39m==\u001b[39m errno\u001b[39m.\u001b[39mENOENT:\n\u001b[1;32m---> 84\u001b[0m         \u001b[39mraise\u001b[39;00m ExecutableNotFound(cmd) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m     85\u001b[0m     \u001b[39mraise\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m quiet \u001b[39mand\u001b[39;00m proc\u001b[39m.\u001b[39mstderr:\n",
      "\u001b[1;31mExecutableNotFound\u001b[0m: failed to execute WindowsPath('dot'), make sure the Graphviz executables are on your systems' PATH"
     ]
    }
   ],
   "source": [
    "import graphviz\n",
    "\n",
    "# Create a new graph\n",
    "graph = graphviz.Digraph()\n",
    "\n",
    "# Add nodes to the graph\n",
    "graph.node(\"A\", \"Development of AI-based prototype for TB detection\")\n",
    "graph.node(\"B\", \"Training the model using CNN and deep learning\")\n",
    "graph.node(\"C\", \"Digital image conversion from 2D to 3D\")\n",
    "graph.node(\"D\", \"Testing and refining the model\")\n",
    "graph.node(\"E\", \"Development of user-friendly GUI\")\n",
    "graph.node(\"F\", \"Report generation based on model findings\")\n",
    "graph.node(\"G\", \"Refinement of the model for other respiratory disorders\")\n",
    "\n",
    "# Add edges to the graph\n",
    "graph.edge(\"A\", \"B\")\n",
    "graph.edge(\"B\", \"C\")\n",
    "graph.edge(\"B\", \"D\")\n",
    "graph.edge(\"D\", \"E\")\n",
    "graph.edge(\"D\", \"F\")\n",
    "graph.edge(\"G\", \"F\")\n",
    "\n",
    "# Render the graph to a file\n",
    "graph.render(\"day_to_day_responsibilities_flowchart\", format=\"png\")\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d1c9bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
